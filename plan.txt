I would like to begin work on a new project called BURST (BTRFS Ultrafast Restore From S3 Transfers).
The project's main goal will be to transform an archive file in S3 object storage to a file tree on
a BTRFS filesystem as quickly as technically possible.

There are at least three key ideas to leverage in achieving this goal:
 1. Utilize best available S3 download performance optimizations. These include:
    a) S3 read performance scales nearly linearly with number of ranged requests sent concurrently for
    parts of the object, especially when those ranged requests are aligned to 8 or 16 MiB offsets
    from the beginning of the object and when parts with identically aligned boundaries were originally
    uploaded to S3 using the multipart upload API.
    b) Other micro-optimizations, especially when running on EC2 instances (which is our objective) are
    captured by the C S3 client at https://github.com/awslabs/aws-c-s3/. We should use this client.
 2. BTRFS supports an ioctl called BTRFS_IOC_ENCODED_WRITE which allows one to write pre-compressed data
    to the filesystem as (possibly part of) the content of a file. BTRFS has certain restrictions on what
    kind of compression algorithms and settings it supports, but if you comply with these restrictions,
    you can write compressed data directly to disk that is decompressed by BTRFS on read. We want to use
    this idea to compress the data in S3 identically to how it will be compressed after being restored on
    disk. In doing so, we gain performance benefits of less network transfer and less disk write bandwidth
    required, and avoid bottlnecking at the CPU to compress the data for BTRFS.

    We will use Zstandard as the compression algorithm because of its high performance and support by BTRFS.
 3. While concurrently transferring parts from S3, avoid needing to buffer large amounts of data in memory.
    Instead, utilize the features of zip archive headers/directories and zstandard skippable frames so that, after reading
    the zip file's central directory at its end, we are able to know where to write the data to disk at the beginning of
    every 8 MiB'th part of the S3 object.

    By doing this, we can simultaneously receive data and write it to its final home on disk, instead of doing
    these two operations sequentially. We also are more memory efficient.

A secondary, but still important, goal of the project will be that its archive files saved to S3 should be able
to be interpreted by any regular zip archive extraction software that supports Zstandard compression. (Note that
there are few such implementations currently; we can use [7-Zip-zstd](https://github.com/mcmilk/7-Zip-zstd) to
verify this goal is being achieved.)

Consequently, the project will require creating three primary deliverable artifacts:
 1. A full specification of an archive format that:
    a) Is supported by zip extractors that support Zstandard
    b) Limits its use of zstandard to the subset of frame sizes, compression levels, etc. that BTRFS supports
       for transparent decompression on read. This includes Zstandard frame sizes that do not exceed 128KiB,
       and compression levels must be between -15 through 15.
    c) To avoid buffering downloaded data when concurrently transferring each 8MiB part, arranges for it to be
       possible to know, having read the zip file's central directory, the details of the BTRFS_IOC_ENCODED_WRITE
       ioctl to issue corresponding to the data at the begining of each 8MiB part.

 2. An archive writer software that transforms filesystem trees on mounted filesystems into archive byte streams
    compliant with the specification. (Note, the writer need not exhibit optimizations like concurrency. Simply
    outputting the compliant archive file byte stream to an unseekable stream writer is sufficient.)

 3. An archive downloader and writer that uses https://github.com/awslabs/aws-c-s3/ to obtain archive byte streams
    from S3 concurrently in parts and issue BTRFS_IOC_ENCODED_WRITE calls to load the downloaded data onto the filesystem.
